{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from collections import defaultdict\n",
    "import pdb\n",
    "import torch.distributions as tdist\n",
    "import matplotlib\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_sampler(num_samples, num_mixtures, mean, cov, mix_coeffs):\n",
    "    z = np.random.multinomial(num_samples, mix_coeffs)\n",
    "\n",
    "    samples = np.zeros(shape=[num_samples, len(mean[0])])\n",
    "    target = np.zeros(shape=[num_samples])\n",
    "    \n",
    "    i_start = 0\n",
    "    data = []\n",
    "    for i in range(len(mix_coeffs)):\n",
    "        i_end = i_start + z[i]\n",
    "        samples[i_start:i_end, :] = np.random.multivariate_normal(\n",
    "            mean=np.array(mean)[i, :],\n",
    "            cov=np.diag(np.array(cov)[i, :]),            \n",
    "            size=z[i])\n",
    "        \n",
    "        target[i_start:i_end] = i\n",
    "\n",
    "        for j in range(i_start,i_end):\n",
    "            data.append({\"x\":samples[j],\"class\":target[j]})\n",
    "        i_start = i_end\n",
    "   \n",
    "    return data\n",
    "\n",
    "\n",
    "class SynthDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_set_len, train_set):\n",
    "        self.train_set_len = train_set_len\n",
    "        self.train_set = train_set\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.train_set_len  \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.train_set[idx]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 10\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "\n",
    "inputdim=2\n",
    "num_mixtures = 5\n",
    "radius = 2.0\n",
    "std = 0.01\n",
    "thetas = np.linspace(0, 2 * np.pi, num_mixtures + 1)[:num_mixtures]\n",
    "xs, ys = radius * np.sin(thetas), radius * np.cos(thetas)\n",
    "mix_coeffs = [1./num_mixtures for i in range(num_mixtures)]\n",
    "mean=tuple(zip(xs, ys))\n",
    "cov=tuple([(std, std)] * num_mixtures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = 'JS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "train_set_len = 10000\n",
    "train_set = gmm_sampler(train_set_len, num_mixtures, mean, cov, mix_coeffs)\n",
    "\n",
    "synthdataset = SynthDataset(train_set_len, train_set)\n",
    "dataloader = DataLoader(synthdataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4) \n",
    "if div == 'KL':\n",
    "    def activation_func(x):\n",
    "        return x\n",
    "\n",
    "    def conjugate(x):\n",
    "        return torch.exp(x - 1)\n",
    "\n",
    "elif div == 'Reverse-KL':\n",
    "    def activation_func(x):\n",
    "        return -torch.exp(-x)\n",
    "\n",
    "    def conjugate(x):\n",
    "        return -1 - torch.log(-x)\n",
    "\n",
    "elif div == 'JS':\n",
    "    def activation_func(x):\n",
    "        return torch.log(2.0 / (1 + torch.exp(-x)))\n",
    "\n",
    "    def conjugate(x):\n",
    "        return -torch.log(2 - torch.exp(x))\n",
    "elif div == 'Pearson':\n",
    "    def activation_func(x):\n",
    "        return x\n",
    "\n",
    "    def conjugate(x):\n",
    "        return 0.25 * torch.pow(x, 2) + x\n",
    "elif div == 'Total-Variation':\n",
    "    def activation_func(x):\n",
    "        return 0.5 * torch.tanh(x)\n",
    "\n",
    "    def conjugate(x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def g_loss(d_fake_score):\n",
    "    g_loss_kl = -torch.mean(conjugate(activation_func(d_fake_score)))\n",
    "    return g_loss_kl\n",
    "\n",
    "def d_loss(d_real,d_fake):\n",
    "    return -(torch.mean(activation_func(d_real)) - torch.mean(conjugate(activation_func(d_fake))))\n",
    "\n",
    "\n",
    "def g_loss_nomean(d_fake_score):\n",
    "    g_loss_kl = -conjugate(activation_func(d_fake_score))\n",
    "    return g_loss_kl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')\n",
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()   \n",
    "        \n",
    "        \n",
    "        self.c1 = nn.Linear(nz, 128)\n",
    "        self.c1_bn = nn.BatchNorm1d(128)\n",
    "        self.c1_relu = nn.ReLU(True)\n",
    "        self.c2 = nn.Linear(128, 128)\n",
    "        self.c2_bn = nn.BatchNorm1d(128)\n",
    "        self.c2_relu = nn.ReLU(True)\n",
    "        self.c3 = nn.Linear(128, 2)\n",
    "        self.c3_tanh = nn.Tanh()    \n",
    "        \n",
    "    def forward(self, input_1):\n",
    "        output = self.c1_relu(self.c1_bn(self.c1(input_1)))\n",
    "        output = self.c2_relu(self.c2_bn(self.c2(output)))\n",
    "        output = self.c3(output) # removed tanh because we dont want bounding\n",
    "        return output\n",
    "\n",
    "        \n",
    "class D(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(D, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation_fn = F.relu\n",
    "        self.sigmoid_act = F.sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.map1(x))\n",
    "        x = self.activation_fn(self.map2(x))\n",
    "        return self.map3(x)\n",
    "      \n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "netD = D(2,256,1)\n",
    "netD.to(device)\n",
    "netD.apply(weights_init)  \n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "\n",
    "netG = G()\n",
    "netG.to(device)\n",
    "netG.apply(weights_init)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "meanmatrix = np.matrix(mean)\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.mlab as mlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def g_sample():\n",
    "    with torch.no_grad():\n",
    "        gen_input = torch.randn(batch_size*10, nz, device=device)\n",
    "        g_fake_data = netG(gen_input)\n",
    "        return g_fake_data.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "Tensor = torch.cuda.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor\n",
    "grads=[]\n",
    "xaxis=[]\n",
    "stopeps = [1,2,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 1/11 [00:03<00:33,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:06<00:31,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [00:13<00:24,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [00:21<00:17,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [00:32<00:07,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [00:35<00:03,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:39<00:00,  3.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(11)):\n",
    "      print(epoch)\n",
    "      for i, sample in enumerate(dataloader):\n",
    "            points = Variable(sample['x'].type(Tensor))\n",
    "            targets = Variable((sample['class']).type(LongTensor), requires_grad = False)        \n",
    "            batch_size = points.size(0)\n",
    "\n",
    "            z = torch.randn(batch_size, nz, device=device)\n",
    "\n",
    "            valid = Variable(Tensor(points.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(points.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            real_points = Variable(points.type(Tensor), requires_grad = False) \n",
    "\n",
    "            # Update G\n",
    "\n",
    "            optimizerG.zero_grad()\n",
    "            gen_points = netG(z)\n",
    "            output_d = netD(gen_points)\n",
    "\n",
    "            gloss = g_loss(output_d)\n",
    "            gloss.backward()\n",
    "            optimizerG.step()\n",
    "        \n",
    "            optimizerD.zero_grad()\n",
    "            output_d_fake = netD(gen_points.detach())\n",
    "            output_d_real = netD(real_points)\n",
    "\n",
    "            dloss = d_loss(output_d_real, output_d_fake)\n",
    "            dloss.backward()\n",
    "            optimizerD.step()\n",
    "            \n",
    "            x = np.arange(-4, 4, 0.1)\n",
    "            y = np.arange(-4, 4, 0.1)\n",
    "            X, Y = np.meshgrid(x,y) # X: 80 x 80, Y: 80 x 80\n",
    "            \n",
    "            \n",
    "            if i%50==0:\n",
    "                data = np.array(list(zip(X.flatten(),Y.flatten()))) # data: 6400 x 2\n",
    "                tensordata = Variable(torch.Tensor(data)).cuda()\n",
    "                with torch.no_grad():\n",
    "                    d_output = netD(tensordata)\n",
    "                output_loss = g_loss_nomean(d_output).cpu().numpy().reshape(80,80)\n",
    "                plt.clf()\n",
    "                ax = Axes3D(plt.figure())\n",
    "                surf = ax.plot_surface(X, Y, output_loss, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "                plt.colorbar(surf, shrink=0.5, aspect=5)\n",
    "                plt.savefig('visualize_loss/'+str(epoch)+'_'+str(i)+'.png')\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
